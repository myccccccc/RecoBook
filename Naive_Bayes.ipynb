{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords #Manually download\n",
    "#nltk.download(\"stopwords\")\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "MIN_WORD_COUNT = 25\n",
    "#MODEL = \"GaussianNB\"\n",
    "MODEL = \"MultinomialNB\"\n",
    "\n",
    "reallyfinalbooks = pd.read_csv('reallyfinalbooks.csv')\n",
    "reallyfinalratings = pd.read_csv('reallyfinalratings.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "traintable = pd.pivot_table(data=train, index=\"newuser_id\", columns=\"newbook_id\", values=\"rating\").sort_index(axis=0).sort_index(axis=1)\n",
    "testtable = pd.pivot_table(data=test, index=\"newuser_id\", columns=\"newbook_id\", values=\"rating\").sort_index(axis=0).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y,h):\n",
    "    \"\"\"RMSE\n",
    "    Args:\n",
    "        y: real_table y\n",
    "        h: predicted_table h\n",
    "    Returns:\n",
    "        RMSE\n",
    "    \"\"\"\n",
    "    a = y-h\n",
    "    a = a.reshape(a.size)\n",
    "    a = a[~np.isnan(a)]\n",
    "\n",
    "    return np.sqrt(sum(a**2)/len(a))\n",
    "\n",
    "def dcg_k(r, k):\n",
    "    \"\"\" Discounted Cumulative Gain (DGC)  \n",
    "    Args:\n",
    "        r: True Ratings in Predicted Rank Order (1st element is top recommendation)\n",
    "        k: Number of results to consider\n",
    "    Returns:\n",
    "        DCG\n",
    "    \"\"\"\n",
    "  \n",
    "    r = np.asfarray(r)[:k]\n",
    "    return np.sum(2**r / np.log2(np.arange(2, r.size + 2)))      \n",
    "\n",
    "\n",
    "\n",
    "def ndcg_k(r, k=20):\n",
    "    \"\"\"Normalized Discounted Cumulative Gain (NDCG)\n",
    "    Args:\n",
    "        r: True Ratings in Predicted Rank Order (1st element is top recommendation)\n",
    "        k: Number of results to consider\n",
    "    Returns:\n",
    "        NDCG\n",
    "    \"\"\"\n",
    "    dcg_max = dcg_k(sorted(r, reverse=True), k)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_k(r, k) / dcg_max\n",
    "\n",
    "def divSco_k(r, tail, k=10):\n",
    "    \"\"\"Diversity Score\n",
    "    Args:\n",
    "        r: bookids in Predicted Rank Order (1st element is top recommendation)\n",
    "        tail: list of less popular/less known books\n",
    "        k: Number of results to consider\n",
    "    Returns:\n",
    "        Diversity Score\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for bookid in r[:k]:\n",
    "        if bookid in tail:\n",
    "            count += 1\n",
    "    return count / k\n",
    "\n",
    "tailcomp = reallyfinalratings[[\"newbook_id\", \"rating\"]].groupby(\"newbook_id\").agg(len).rename(columns={\"rating\":\"count\"}).sort_values(by='count', ascending=False).reset_index()\n",
    "tot = sum(tailcomp['count'])\n",
    "tailcomp['popshare']= [x/tot for x in tailcomp['count']]\n",
    "tailcomp['popsharecumsum']= tailcomp['popshare'].cumsum()\n",
    "tailcomp['category']= ['Head' if x<0.95 else \"Tail\" for x in tailcomp['popsharecumsum']]\n",
    "tail = tailcomp[tailcomp['category'] == 'Tail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reallyfinalbooks[\"description_list\"] = (reallyfinalbooks[\"description\"]\n",
    "                                        .replace(\"Unknown\", np.NaN)\n",
    "                                        .fillna(reallyfinalbooks[\"title_without_series\"])\n",
    "                                        .str.replace(r'[^\\w\\s\\']',\"\")\n",
    "                                        .str.lower()\n",
    "                                        .str.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allwords = []\n",
    "for l in reallyfinalbooks[\"description_list\"]:\n",
    "    allwords += l\n",
    "wordcounts = pd.DataFrame({\"count\": allwords})[\"count\"].value_counts().to_frame().sort_values(by=\"count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordbag = []\n",
    "for word in wordcounts.index:\n",
    "    if wordcounts.loc[word, \"count\"] >= MIN_WORD_COUNT and word not in stopwords.words(\"english\") and len(word) > 1:\n",
    "        wordbag.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def deslist2desvector(wb, l):\n",
    "    v = []\n",
    "    for word in wb:\n",
    "        count = l.count(word)\n",
    "        v.append(count)\n",
    "    return [np.array(v)]\n",
    "\n",
    "reallyfinalbooks[\"description_vector\"] = reallyfinalbooks[\"description_list\"].apply(lambda l: deslist2desvector(wordbag, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\data100\\lib\\site-packages\\sklearn\\naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "Wall time: 1h 41min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "userid2preds = {}\n",
    "userid2pred_ratings = {}\n",
    "userids = list(reallyfinalratings[\"newuser_id\"].unique())\n",
    "\n",
    "\n",
    "for counter, userid in enumerate(userids):\n",
    "    if (counter % 500 == 0):\n",
    "        print(counter)\n",
    "    userid2usertraindata = train[train[\"newuser_id\"] == userid].merge(reallyfinalbooks, on=\"newbook_id\", how=\"left\")\n",
    "    userclass = np.sort(userid2usertraindata[\"rating\"].unique())\n",
    "    if len(userclass) == 1:\n",
    "        userclass = np.append(userclass, [0])\n",
    "    m = MultinomialNB(alpha = 0.1) if MODEL == \"MultinomialNB\" else GaussianNB()\n",
    "    m.fit(np.concatenate(userid2usertraindata[\"description_vector\"]), userid2usertraindata[\"rating\"])\n",
    "    pred =  (reallyfinalbooks[[\"newbook_id\"]]\n",
    "            .assign(pred_rating=(m.predict_proba(np.concatenate(reallyfinalbooks[\"description_vector\"])) @ userclass))\n",
    "            .sort_values(by=\"pred_rating\", ascending=False)\n",
    "            .assign(rank=np.arange(1, len(reallyfinalbooks)+1))\n",
    "            .sort_values(by=\"newbook_id\")\n",
    "            .set_index(\"newbook_id\"))\n",
    "    userid2preds[userid] = pred\n",
    "    userid2pred_ratings[userid] = pred[\"pred_rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred_table = pd.DataFrame.from_dict(userid2pred_ratings, orient=\"index\", columns=range(1, len(reallyfinalbooks)+1))\n",
    "pred_table = pred_table.sort_index(axis=0).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_rmse = rmse(traintable.values, pred_table.values)\n",
    "test_rmse = rmse(testtable.values, pred_table.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "userids = reallyfinalratings[\"newuser_id\"].unique()\n",
    "train_rs = []\n",
    "test_rs = []\n",
    "for userid in userids:\n",
    "    train_rs.append(train[train[\"newuser_id\"] == userid].merge(userid2preds[userid], on=\"newbook_id\", how=\"left\").sort_values(by=\"rank\")[\"rating\"])\n",
    "    test_rs.append(test[test[\"newuser_id\"] == userid].merge(userid2preds[userid], on=\"newbook_id\", how=\"left\").sort_values(by=\"rank\")[\"rating\"])\n",
    "\n",
    "train_ndgc = np.mean([ndcg_k(r) for r in train_rs])\n",
    "test_ndgc = np.mean([ndcg_k(r) for r in test_rs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "diversityScore = np.mean([divSco_k(pred.sort_values(by=\"rank\").index,tail[\"newbook_id\"].values) for pred in list(userid2preds.values())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Model\n",
      "RMSE for train data: 0.057, test data: 1.194\n",
      "nDGC for train data: 1.000, test data: 0.807\n",
      "Diversity Score: 0.092\n"
     ]
    }
   ],
   "source": [
    "print(\"NB Model\")\n",
    "print(\"RMSE for train data: {:.3f}, test data: {:.3f}\".format(train_rmse, test_rmse))\n",
    "print(\"nDGC for train data: {:.3f}, test data: {:.3f}\".format(train_ndgc, test_ndgc))\n",
    "print(\"Diversity Score: {:.3f}\".format(diversityScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
